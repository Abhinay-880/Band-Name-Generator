{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG5nGocc53iVWIOGQ5l1Iv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinay-880/Band-Name-Generator/blob/main/Prompt_Engineering_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Engineering"
      ],
      "metadata": {
        "id": "kRyxmfpNh5En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  What is a Prompt?\n",
        "\n",
        "    A prompt is simply the instruction or input you give to an AI to get a response.\n",
        "\n",
        "-  What is Prompt Engineering?\n",
        "    The art of designing inputs to guide AI for optimal responses."
      ],
      "metadata": {
        "id": "P9HZNBXfiHjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advantages of Prompt Engineering\n",
        "\n",
        "- Faster\n",
        "- Saves Time\n",
        "- Smater\n",
        "- Effective way of using AI"
      ],
      "metadata": {
        "id": "J7wGRvQOiq9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to do Preparing Prompt\n",
        "\n",
        "üîπ 1. Context\n",
        "\n",
        "    üëâ Definition: Extra background information you give to the AI so it understands better.\n",
        "    üëâ Example Prompt:\n",
        "    \"You are helping a 5th-grade student. Explain the water cycle in simple words.\"\n",
        "\n",
        "    Here, the context = ‚ÄúYou are helping a 5th-grade student.‚Äù\n",
        "\n",
        "üîπ 2. Role\n",
        "\n",
        "    üëâ Definition: Telling the AI who it should act as.\n",
        "    üëâ Example Prompt:\n",
        "    \"Act as a math teacher. Explain fractions with a real-life example.\"\n",
        "\n",
        "    Here, the role = ‚Äúmath teacher.‚Äù\n",
        "\n",
        "üîπ 3. Constraints\n",
        "\n",
        "    üëâ Definition: Rules or limits you set for the AI‚Äôs answer.\n",
        "    üëâ Example Prompt:\n",
        "    \"Explain Newton‚Äôs laws in 3 bullet points only.\"\n",
        "\n",
        "    Here, the constraint = ‚Äú3 bullet points only.‚Äù\n",
        "\n",
        "üîπ 4. Instructions\n",
        "\n",
        "    üëâ Definition: Clear directions on what exactly you want.\n",
        "    üëâ Example Prompt:\n",
        "    \"Write a 2-line summary of this article in simple English.\"\n",
        "\n",
        "    Here, the instruction = ‚ÄúWrite a 2-line summary.‚Äù\n",
        "\n",
        "üîπ 5. Language of Chain (Zero-shot & Few-shot)\n",
        "\n",
        "    ‚ú® Zero-shot Prompting\n",
        "\n",
        "    üëâ Definition: You don‚Äôt give examples; you just ask directly.\n",
        "    üëâ Example Prompt:\n",
        "    \"Translate this sentence into French: I love apples.\"\n",
        "\n",
        "    ‚ú® Few-shot Prompting\n",
        "\n",
        "    üëâ Definition: You give a few examples to guide the AI.\n",
        "    üëâ Example Prompt:\n",
        "    *\"Translate into French:\n",
        "\n",
        "    I love apples ‚Üí J‚Äôaime les pommes\n",
        "\n",
        "    I like dogs ‚Üí J‚Äôaime les chiens\n",
        "    Now translate: I eat rice.\"*"
      ],
      "metadata": {
        "id": "F1en5qJSjWEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìù Problems for Practice\n",
        "\n",
        "Explain Concept\n",
        "üëâ Problem: Explain ‚Äúgravity‚Äù to a 10-year-old in simple words with a real-life example.\n",
        "\n",
        "my-prompt - \"You are a teacher. Explain the concept of gravity to a 10-year-old student. Keep the explanation simple, use real-world examples (like throwing a stone in the sky and it comes back down). Do not use any math or scientific values. Use only simple words.\"\n",
        "\n",
        "Summarization\n",
        "üëâ Problem: Summarize a long paragraph into 3 short bullet points.\n",
        "\n",
        "Creative Writing\n",
        "üëâ Problem: Write a very short story (3‚Äì4 lines) about a dog who becomes a hero.\n",
        "\n",
        "Translation\n",
        "üëâ Problem: Translate the sentence ‚ÄúI am learning English‚Äù into Hindi.\n",
        "\n",
        "Coding Help\n",
        "üëâ Problem: Write a Python function that finds the factorial of a number."
      ],
      "metadata": {
        "id": "Cfln7_jylrdB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ni-JX3XmbM8l"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('prompt')"
      ],
      "metadata": {
        "id": "UXo4r0PRcRqD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "UN_guJdudQBI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_templet = \"\"\"\n",
        "#   Context: You are helping a customer service team understand customer feedback from reviews\n",
        "#   Role : You are a sentiment analysis AI assistant\n",
        "#   Constrains\n",
        "#     - No Explanation\n",
        "#     - Review will be in single sentence\n",
        "#     - Output must be exactly one word\n",
        "#   Instructions\n",
        "#     Read the input review and classify the sentiment\n",
        "#     Respond only with One word\n",
        "#         Positive\n",
        "#         Negative\n",
        "#         Neutral\n",
        "#     Examples\n",
        "#       User: The product was amazing and arrived on time\n",
        "#       Assistant: Positive\n",
        "#       User: This is the worst thing I ever bought\n",
        "#       Assistant: Negative\n",
        "#       User: It's Okay, Nothing special but not bad either\n",
        "#       Assistant: Neutral\n",
        "#       Now classify this below review\n",
        "#       User: I expect more from the product, but it works\n",
        "#       Assistant:\n",
        "# \"\"\""
      ],
      "metadata": {
        "id": "Avdjwb_xde3E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_templet = \"\"\"\n",
        "\"You are a teacher. Explain the concept of gravity to a 10-year-old student. Keep the explanation simple, use real-world examples (like throwing a stone in the sky and it comes back down). Do not use any math or scientific values. Use only simple words.\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UC5fYgW-l8tr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "f3ga3pNlfLhh",
        "outputId": "d54d3df3-208e-4a08-da2a-32e22555e2ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.5-pro-preview-03-25',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-03-25',\n",
              "       display_name='Gemini 2.5 Pro Preview 03-25',\n",
              "       description='Gemini 2.5 Pro Preview 03-25',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-preview-05-20',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-20',\n",
              "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.5 Flash',\n",
              "       description=('Stable version of Gemini 2.5 Flash, our mid-size multimodal model that '\n",
              "                    'supports up to 1 million tokens, released in June of 2025.'),\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-lite-preview-06-17',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-06-17',\n",
              "       display_name='Gemini 2.5 Flash-Lite Preview 06-17',\n",
              "       description='Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro-preview-05-06',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-06',\n",
              "       display_name='Gemini 2.5 Pro Preview 05-06',\n",
              "       description='Preview release (May 6th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro-preview-06-05',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-06-05',\n",
              "       display_name='Gemini 2.5 Pro Preview',\n",
              "       description='Preview release (June 5th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro',\n",
              "       base_model_id='',\n",
              "       version='2.5',\n",
              "       display_name='Gemini 2.5 Pro',\n",
              "       description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash',\n",
              "       description='Gemini 2.0 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in January of 2025.'),\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp-image-generation',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
              "       description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite 001',\n",
              "       description='Stable version of Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite',\n",
              "       description='Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-preview-image-generation',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Preview Image Generation',\n",
              "       description='Gemini 2.0 Flash Preview Image Generation',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-pro-exp',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.0 Pro Experimental',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-pro-exp-02-05',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.0 Pro Experimental 02-05',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-20',\n",
              "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-20',\n",
              "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-20',\n",
              "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-preview-tts',\n",
              "       base_model_id='',\n",
              "       version='gemini-2.5-flash-exp-tts-2025-05-19',\n",
              "       display_name='Gemini 2.5 Flash Preview TTS',\n",
              "       description='Gemini 2.5 Flash Preview TTS',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=16384,\n",
              "       supported_generation_methods=['countTokens', 'generateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro-preview-tts',\n",
              "       base_model_id='',\n",
              "       version='gemini-2.5-pro-preview-tts-2025-05-19',\n",
              "       display_name='Gemini 2.5 Pro Preview TTS',\n",
              "       description='Gemini 2.5 Pro Preview TTS',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=16384,\n",
              "       supported_generation_methods=['countTokens', 'generateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-2.0-flash-experimental',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='LearnLM 2.0 Flash Experimental',\n",
              "       description='LearnLM 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=32768,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-1b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 1B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-4b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 4B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-12b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 12B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-27b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 27B',\n",
              "       description='',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3n-e4b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3n E4B',\n",
              "       description='',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3n-e2b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3n E2B',\n",
              "       description='',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-lite',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.5 Flash-Lite',\n",
              "       description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-image-preview',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Nano Banana',\n",
              "       description='Gemini 2.5 Flash Preview Image',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=1.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp-03-07',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental 03-07',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40),\n",
              " Model(name='models/imagen-3.0-generate-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Imagen 3.0',\n",
              "       description='Vertex served Imagen 3.0 002 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/imagen-4.0-generate-preview-06-06',\n",
              "       base_model_id='',\n",
              "       version='01',\n",
              "       display_name='Imagen 4 (Preview)',\n",
              "       description='Vertex served Imagen 4.0 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/imagen-4.0-ultra-generate-preview-06-06',\n",
              "       base_model_id='',\n",
              "       version='01',\n",
              "       display_name='Imagen 4 Ultra (Preview)',\n",
              "       description='Vertex served Imagen 4.0 ultra model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/imagen-4.0-generate-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Imagen 4',\n",
              "       description='Vertex served Imagen 4.0 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/imagen-4.0-ultra-generate-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Imagen 4 Ultra',\n",
              "       description='Vertex served Imagen 4.0 ultra model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/imagen-4.0-fast-generate-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Imagen 4 Fast',\n",
              "       description='Vertex served Imagen 4.0 Fast model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/veo-2.0-generate-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Veo 2',\n",
              "       description=('Vertex served Veo 2 model. Access to this model requires billing to be '\n",
              "                    'enabled on the associated Google Cloud Platform account. Please visit '\n",
              "                    'https://console.cloud.google.com/billing to enable it.'),\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predictLongRunning'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/veo-3.0-generate-preview',\n",
              "       base_model_id='',\n",
              "       version='3.0',\n",
              "       display_name='Veo 3',\n",
              "       description='Veo 3 preview.',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predictLongRunning'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/veo-3.0-fast-generate-preview',\n",
              "       base_model_id='',\n",
              "       version='3.0',\n",
              "       display_name='Veo 3 fast',\n",
              "       description='Veo 3 fast preview.',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predictLongRunning'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/veo-3.0-generate-001',\n",
              "       base_model_id='',\n",
              "       version='3.0',\n",
              "       display_name='Veo 3',\n",
              "       description='Veo 3',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predictLongRunning'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/veo-3.0-fast-generate-001',\n",
              "       base_model_id='',\n",
              "       version='3.0',\n",
              "       display_name='Veo 3 fast',\n",
              "       description='Veo 3 fast',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predictLongRunning'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-2.5-flash-preview-native-audio-dialog',\n",
              "       base_model_id='',\n",
              "       version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19',\n",
              "       display_name='Gemini 2.5 Flash Preview Native Audio Dialog',\n",
              "       description='Gemini 2.5 Flash Preview Native Audio Dialog',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog',\n",
              "       base_model_id='',\n",
              "       version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19',\n",
              "       display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog',\n",
              "       description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-live-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description='Gemini 2.0 Flash 001',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-live-2.5-flash-preview',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini Live 2.5 Flash Preview',\n",
              "       description='Gemini Live 2.5 Flash Preview',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-live-preview',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.5 Flash Live Preview',\n",
              "       description='Gemini 2.5 Flash Live Preview',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "JuFCA7mwfrlC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(prompt_templet)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Lsio-vM2gM14",
        "outputId": "1d98a982-7b6d-4325-da99-be473247c217"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, imagine you have a bouncy ball. What happens when you throw it up in the air?\n",
            "\n",
            "That's right! It comes back down. That's because of something called **gravity**.\n",
            "\n",
            "Think of it like this: Everything on Earth, even you and me, is being pulled towards the ground by gravity. It's like the Earth is a big, giant magnet, and everything around it is made of metal! The Earth is pulling everything towards its center.\n",
            "\n",
            "When you throw that bouncy ball up, you're giving it a little push against gravity. But gravity is still there, pulling it back down. So, the ball goes up for a little bit, but then gravity wins, and it comes zooming back to Earth.\n",
            "\n",
            "It's the same reason you don't float away into space! Gravity is holding you right here on the ground. It's what keeps our feet firmly planted.\n",
            "\n",
            "Even the air we breathe stays close to the Earth because of gravity. It's why water flows down a hill instead of up.\n",
            "\n",
            "So, gravity is a force, kind of like an invisible rope, that pulls everything towards the Earth. It's what keeps us all grounded! Any questions?\n",
            "\n"
          ]
        }
      ]
    }
  ]
}